{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-04-10T13:38:30.235760Z",
     "iopub.status.busy": "2023-04-10T13:38:30.235370Z",
     "iopub.status.idle": "2023-04-10T13:40:00.889810Z",
     "shell.execute_reply": "2023-04-10T13:40:00.888523Z",
     "shell.execute_reply.started": "2023-04-10T13:38:30.235702Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install gdown\n",
    "!pip install monai[all]==1.1.0\n",
    "!pip install torch trochvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T13:40:00.892807Z",
     "iopub.status.busy": "2023-04-10T13:40:00.892289Z",
     "iopub.status.idle": "2023-04-10T13:40:09.211258Z",
     "shell.execute_reply": "2023-04-10T13:40:09.210331Z",
     "shell.execute_reply.started": "2023-04-10T13:40:00.892764Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import gdown\n",
    "from glob import glob\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from monai.config import print_config\n",
    "from monai.transforms import (\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    Resized,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandGaussianNoised,\n",
    "    RandCropByPosNegLabeld,\n",
    "    ScaleIntensityRanged,\n",
    "    ScaleIntensityd,\n",
    "    Spacingd,\n",
    "    RandRotated,\n",
    "    ToTensord,\n",
    "    RandAffined,\n",
    "    Activations,\n",
    "    AsDiscrete,\n",
    "    EnsureTyped\n",
    ")\n",
    "\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\n",
    "from monai.utils import first\n",
    "from monai.losses import DiceLoss, DiceFocalLoss\n",
    "from monai.metrics import DiceMetric, MeanIoU\n",
    "from monai.networks.nets import SwinUNETR, UNETR\n",
    "from monai.networks.layers import Norm\n",
    "from monai.inferers import sliding_window_inference\n",
    "\n",
    "import torch\n",
    "\n",
    "# %env PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512\n",
    "is_cuda = torch.cuda.is_available()\n",
    "device = \"cuda\" if(is_cuda) else \"cpu\"\n",
    "if(is_cuda):\n",
    "    torch.cuda.empty_cache()\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">Note</span>\n",
    "\n",
    "Download data from [drive](https://drive.google.com/file/d/1yU_MeDoMHnLg0vNAy4Hb7_liJBogWl_N/view?usp=share_link) link and save the data in `/data` folder.\n",
    "\n",
    "Folder Structure\n",
    "\n",
    "```txt\n",
    "├── data\n",
    "    ├── imageTr        \n",
    "    ├── labelsTR     \n",
    "    └── test      \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"data\", exist_ok=True)\n",
    "os.makedirs(\"model\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T13:41:15.530235Z",
     "iopub.status.busy": "2023-04-10T13:41:15.529528Z",
     "iopub.status.idle": "2023-04-10T13:41:15.535243Z",
     "shell.execute_reply": "2023-04-10T13:41:15.534044Z",
     "shell.execute_reply.started": "2023-04-10T13:41:15.530195Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT_DATA_FOLDER=r\"data\"\n",
    "IMAGE_FOLDER=r\"imagesTr\"\n",
    "LABEL_FOLDER=r\"labelsTr\"\n",
    "TEST_FOLDER=r\"test\"\n",
    "ROOT_MODEL_DIR=r\"model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T13:41:16.600770Z",
     "iopub.status.busy": "2023-04-10T13:41:16.600069Z",
     "iopub.status.idle": "2023-04-10T13:41:16.612638Z",
     "shell.execute_reply": "2023-04-10T13:41:16.611503Z",
     "shell.execute_reply.started": "2023-04-10T13:41:16.600725Z"
    }
   },
   "outputs": [],
   "source": [
    "image_path = sorted(glob(os.path.join(ROOT_DATA_FOLDER, IMAGE_FOLDER, \"*.nii.gz\")))\n",
    "label_path = sorted(glob(os.path.join(ROOT_DATA_FOLDER, LABEL_FOLDER, \"*.nii.gz\")))\n",
    "test_path = sorted(glob(os.path.join(ROOT_DATA_FOLDER, TEST_FOLDER, \"*.nii.gz\")))\n",
    "\n",
    "data_path = [{\"image\": image_name, \"label\": label_name} for image_name, label_name in zip(image_path, label_path)]\n",
    "test_path = [{\"image\": image_name} for image_name in test_path]\n",
    "\n",
    "print(\"Total Train Data: \", len(data_path))\n",
    "print(\"Total Test Data: \", len(test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T13:41:17.712031Z",
     "iopub.status.busy": "2023-04-10T13:41:17.711297Z",
     "iopub.status.idle": "2023-04-10T13:41:17.717671Z",
     "shell.execute_reply": "2023-04-10T13:41:17.716549Z",
     "shell.execute_reply.started": "2023-04-10T13:41:17.711991Z"
    }
   },
   "outputs": [],
   "source": [
    "val_path = data_path[:3]\n",
    "val_path += data_path[len(data_path)-1:]\n",
    "train_path = [i for i in data_path if i not in val_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T13:41:19.084901Z",
     "iopub.status.busy": "2023-04-10T13:41:19.084509Z",
     "iopub.status.idle": "2023-04-10T13:41:19.169664Z",
     "shell.execute_reply": "2023-04-10T13:41:19.168679Z",
     "shell.execute_reply.started": "2023-04-10T13:41:19.084866Z"
    }
   },
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.0, 1.0, 1.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        ScaleIntensityd(keys=[\"image\"]),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        Resized(\n",
    "            keys=[\"image\", \"label\"], \n",
    "            spatial_size=(128, 128, 64), \n",
    "            mode=('trilinear', 'nearest')\n",
    "        ),\n",
    "        RandAffined(\n",
    "            keys=['image', 'label'],\n",
    "            mode=('bilinear', 'nearest'),\n",
    "            prob=0.6, spatial_size=(128, 128, 64),\n",
    "            rotate_range=(0, 0, np.pi/12),\n",
    "            scale_range=(0.1, 0.1, 0.1)\n",
    "        ),\n",
    "        RandRotated(keys=['image', 'label'], prob=0.5, range_x=10.0),\n",
    "        RandGaussianNoised(keys='image', prob=0.5),\n",
    "        ToTensord(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.0, 1.0, 1.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        ScaleIntensityd(keys=[\"image\"]),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        Resized(\n",
    "            keys=[\"image\", \"label\"], \n",
    "            spatial_size=(128, 128, 64), \n",
    "            mode=('trilinear', 'nearest')\n",
    "        ),\n",
    "        ToTensord(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\"]),\n",
    "        EnsureTyped(keys=[\"image\"]),\n",
    "        Orientationd(keys=[\"image\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\"],\n",
    "            pixdim=(1.0, 1.0, 1.0),\n",
    "            mode=(\"bilinear\"),\n",
    "        ),\n",
    "        ScaleIntensityd(keys=[\"image\"]),\n",
    "        CropForegroundd(keys=[\"image\"], source_key=\"image\"),\n",
    "        Resized(\n",
    "            keys=[\"image\"], \n",
    "            spatial_size=(128, 128, 64), \n",
    "            mode=('trilinear')\n",
    "        ),\n",
    "        ToTensord(keys=[\"image\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T13:41:20.417134Z",
     "iopub.status.busy": "2023-04-10T13:41:20.416155Z",
     "iopub.status.idle": "2023-04-10T13:41:20.433680Z",
     "shell.execute_reply": "2023-04-10T13:41:20.432758Z",
     "shell.execute_reply.started": "2023-04-10T13:41:20.417085Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size=1\n",
    "worker=0\n",
    "train_dataset = Dataset(data=train_path, transform=train_transforms)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=worker)\n",
    "\n",
    "val_dataset = Dataset(data=val_path, transform=val_transforms)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=worker)\n",
    "\n",
    "test_dataset = Dataset(data=test_path, transform=test_transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T13:41:21.712811Z",
     "iopub.status.busy": "2023-04-10T13:41:21.711791Z",
     "iopub.status.idle": "2023-04-10T13:41:21.719019Z",
     "shell.execute_reply": "2023-04-10T13:41:21.717938Z",
     "shell.execute_reply.started": "2023-04-10T13:41:21.712771Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_model(path, model, optimizer, train_loss, val_metric):\n",
    "    data = {\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'train_loss': train_loss,\n",
    "        'val_metric': val_metric,\n",
    "    }\n",
    "    \n",
    "    torch.save(data, path)\n",
    "\n",
    "def load_model(path):\n",
    "    data = torch.load(path, map_location=device)\n",
    "    \n",
    "    model_state = data['model']\n",
    "    optimizer_state = data['optimizer']\n",
    "    train_loss = data['train_loss']\n",
    "    val_metric = data['val_metric']\n",
    "    \n",
    "    return (model_state, optimizer_state, train_loss, val_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T13:41:24.115935Z",
     "iopub.status.busy": "2023-04-10T13:41:24.115212Z",
     "iopub.status.idle": "2023-04-10T13:41:28.187329Z",
     "shell.execute_reply": "2023-04-10T13:41:28.186158Z",
     "shell.execute_reply.started": "2023-04-10T13:41:24.115896Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "max_epochs = 100\n",
    "val_interval = 1\n",
    "gradient_accumulations = 2\n",
    "\n",
    "model = UNETR(\n",
    "    img_size=(128, 128, 64),\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    "    dropout_rate=0.5\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-3, weight_decay=1e-5)\n",
    "\n",
    "loss_function = DiceLoss(sigmoid=True, to_onehot_y=True, include_background=False)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epochs)\n",
    "\n",
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
    "\n",
    "post_pred = Compose([AsDiscrete(argmax=True, to_onehot=2)])\n",
    "post_label = Compose([AsDiscrete(to_onehot=2)])\n",
    "\n",
    "if(is_cuda):\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T13:41:28.190391Z",
     "iopub.status.busy": "2023-04-10T13:41:28.189522Z",
     "iopub.status.idle": "2023-04-10T13:41:31.257675Z",
     "shell.execute_reply": "2023-04-10T13:41:31.256539Z",
     "shell.execute_reply.started": "2023-04-10T13:41:28.190360Z"
    }
   },
   "outputs": [],
   "source": [
    "# load model if saved\n",
    "model_file = \"\" ## model name if saved\n",
    "path = os.path.join(ROOT_MODEL_DIR, model_file)\n",
    "\n",
    "if(model_file!=\"\" && os.path.isfile(path)):\n",
    "    model_state, optimizer_state, train_loss, val_metric = load_model(path)\n",
    "    model.load_state_dict(model_state)\n",
    "    optimizer.load_state_dict(optimizer_state)\n",
    "    best_metric = max(val_metric)\n",
    "else:\n",
    "    train_loss, val_metric = np.array([]), np.array([])\n",
    "    best_metric = -1\n",
    "\n",
    "best_metric_epoch = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T13:41:34.216482Z",
     "iopub.status.busy": "2023-04-10T13:41:34.216063Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Total Train: {train_loss.shape[0]}\")\n",
    "print(f\"Best Metric: {best_metric}\")\n",
    "\n",
    "total_start = time.time()\n",
    "for epoch in range(max_epochs):\n",
    "    epoch_start = time.time()\n",
    "    print(\"-\" * 20)\n",
    "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "    \n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    steps = 0\n",
    "\n",
    "    step_start = time.time()\n",
    "    for batch_idx, batch_data in enumerate(train_loader):\n",
    "        steps += 1\n",
    "        inputs=batch_data['image'].to(device)\n",
    "        labels=batch_data['label'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        #forward pass\n",
    "        if is_cuda:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_function(outputs, labels)\n",
    "        else:\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "        \n",
    "        #backward pass\n",
    "        if is_cuda:\n",
    "            scaler.scale(loss).backward()\n",
    "            epoch_loss += loss.item()\n",
    "            scaler.unscale_(optimizer)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            epoch_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        if(steps%20==0):\n",
    "            print(\n",
    "                f\"{steps}/{len(train_dataset) // train_loader.batch_size}\"\n",
    "                f\", train_loss: {loss.item():.4f}\"\n",
    "                f\", step time: {(time.time() - step_start):.4f}\"\n",
    "            )\n",
    "            step_start = time.time()\n",
    "    \n",
    "    lr_scheduler.step()\n",
    "    epoch_loss /= steps\n",
    "    train_loss = np.append(train_loss, epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "    \n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for val_data in val_loader:\n",
    "                val_input = val_data['image'].to(device)\n",
    "                val_labels = val_data['label'].to(device)\n",
    "                \n",
    "                roi_size = (128, 128, 64)\n",
    "                sw_batch_size = 1\n",
    "                \n",
    "                if torch.cuda.is_available():\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        val_outputs = sliding_window_inference(val_input, roi_size, sw_batch_size, model)\n",
    "                else:\n",
    "                    val_outputs = sliding_window_inference(val_input, roi_size, sw_batch_size, model)\n",
    "\n",
    "                val_outputs = [post_pred(i) for i in decollate_batch(val_outputs)]\n",
    "                val_labels = [post_label(i) for i in decollate_batch(val_labels)]\n",
    "                \n",
    "                dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "                \n",
    "            metric = dice_metric.aggregate().item()\n",
    "            dice_metric.reset()\n",
    "            val_metric = np.append(val_metric, metric)\n",
    "            \n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                \n",
    "                # saving model\n",
    "                path = os.path.join(ROOT_MODEL_DIR, f\"unetr_model_without_{metric:.4f}.pth\")\n",
    "                save_model(path, model, optimizer, train_loss, val_metric)\n",
    "                print(\"Saved best model and Optimizer.\")\n",
    "                \n",
    "            print(\n",
    "                f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n",
    "                f\"\\nbest mean dice: {best_metric:.4f}\"\n",
    "                f\" at epoch: {best_metric_epoch}\"\n",
    "            )\n",
    "            \n",
    "    print(f\"time consuming of epoch {epoch + 1} is: {(time.time() - epoch_start):.4f}\")\n",
    "\n",
    "total_time = time.time() - total_start\n",
    "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}, total time: {total_time}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu()\n",
    "\n",
    "checker = first(val_loader)\n",
    "image, label = checker['image'], checker['label']\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(image)\n",
    "    output = torch.nn.Softmax()(output)\n",
    "    output = torch.round(output)\n",
    "\n",
    "    print(f\"Output shape: {output.shape}\")\n",
    "\n",
    "    for slide in range(output.shape[2]):\n",
    "        plt.figure(\"Test Model\", (12, 12))\n",
    "\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.title(\"Input\")\n",
    "        plt.imshow(image[0, 0, :, :, slide], cmap = \"gray\")\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.title(\"Label\")\n",
    "        plt.imshow(image[0, 0, :, :, slide], cmap = \"gray\")\n",
    "        plt.imshow(label[0, 0, :, :, slide], cmap = 'jet', alpha = 0.5)\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.title(\"Output\")\n",
    "        plt.imshow(image[0, 0, :, :, slide], cmap = \"gray\")\n",
    "        plt.imshow(output[0, 1, :, :, slide], cmap = 'jet', alpha = 0.5)\n",
    "\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
